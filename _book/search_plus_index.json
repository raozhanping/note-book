{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction unbuntu 中管理用户和用户组 添加一个用户并指定 id 为1002sudo groupadd -g 1002 www 添加一个用户到 www 组并指定 id 为 1003 sudo useradd wyx -g 1002 -u 1003 -m 修改用户密码 sudo passwd wyx 删除一个用户 sudo userdel wyx 为该用户添加 sudo 权限 sudo usermod -a -G adm wyx sudo usermod -a -G sudo wyx 查看所有用户和用户组： cat /etc/passwd cat /etc/group TODO: async await 是否阻塞問題? "},"docs/cssModules.html":{"url":"docs/cssModules.html","title":"CSS Modules","keywords":"","body":"CSS Modules CSS Modules CSS Modules CSS Modules Usage "},"docs/cssModules-README.html":{"url":"docs/cssModules-README.html","title":"CSS Modules","keywords":"","body":"CSS Modules A CSS Module is a CSS file in which all class names and animation names are scoped locally by default. All URLs (url(...)) and @import are in module request format (./xxx and ../xxx means relative, xxx and xxx/yyy means in modules folder, i.e. in node_modules). CSS Modules compile to a low-level interchange format called ICSS or Interoperable CSS, but are written like normal CSS files: When importing the CSS Module from a JS Module, it exports an object with all mappings from local names to global names. Naming For local class names cameCase naming is recommended, but not enforced. Exceptions :global switches to global scope for the current selector respective identifier. :global(.xxx) respective @keyframes:global(xxx) declares the stuff in parenthesis in the global scope. Similarly, :local and :local(...) for local scope. if the selector is switched into global mode, global mode is activated for the rules.(This allows us to make animation:abc; local) Example: .localA :global .global-b .global-c :local(.localD.localE) .global-d Composition It's possible to compose selectors. .className { color: green; background: red; } .otherClassName { composes: className; color: yellow; } There can be multipe composes rules, but composes rules must be before other rules. Extending works only for local-scoped selectors and only if the selector is a single class name. When a class name composes another class name, the CSS Module exports both class names for the local class. This can add up to multiple class names. It's possible to compose multiple classes with compose: classNameA classNameB. Dependencies It's possible to compose class names from other CSS Modules. .otherClassName { composes: className from \"./style.css\"; } Note that when composing multiple classes from different files the order of appliance is undefined. Make sure to not define different values for the same property in multiple class names from different files when they are composed in a single class. Note that composing should not form a circular dependency. Elsewise it's undefined whether properties of a rule override properties of a composed rule. The module system may emit an error. Usage with preprocessors Perprocessors can make it easy to define a vlock global or local.i.e. with less.js :global { .global-class-name { color: green; } } Why? modular and reusable CSS! No more conflicts. Explicit dependencies. No global scope. Implementations webpack Webpack's css-loader in module mode replaces every local-scoped identifier with a global unique name (hashed from module name and local identifier by default) and exports the used identifier. Extending adds the source class name(s) to the exports. Extending from other modules first imports the other module and then adds the class name(s) to the exports. Server-side and static websites PostCSS-Modules allow to use CSS Modules for static builds and the server side with Ruby, PHP or any other language or framework. "},"docs/cssModules-usage.html":{"url":"docs/cssModules-usage.html","title":"CSS Modules Usage","keywords":"","body":"CSS Modules 为了让 CSS 能够适用软件工程方法，程序员想了各种方法，让他变得像一门编程语言。从最早的 Less、 SASS，到后来的 PostCSS，再到最近的 CSS in JS，都是为了解决这个问题。 而 CSS Modules 不同于上述。他不是将 CSS 改造成编程语言，而是功能很单纯，只加入了局部作用域和模块依赖，这恰恰是网页组件最急需的功能。 局部作用域 CSS 的规则都是全局的，任何一个组件的样式规则，都对整个网页有效。 产生局部作用域的唯一方法，就是使用一个独一无二的 class 的名字，不会与其他选择器重名。这就是 CSS Modules 的做法。 import React from 'react'; import style form './App.css'; export default () => { return ( Hello World! ); } 全局作用域 CSS Modules 允许使用 :global(.className)的语法，声明一个全局规则。凡是这样声明的class，都不会被编译成hash字符串。 .title { color: red; } :global(.title) { color: green; } import React from 'react'; import styles from './App.css'; export defalut () => { return ( Hello World ); } 定制哈希类明 css-loader 默认的哈希算法是[hash:base64]，这会将.title编译成._3zyde4l1yATCOkgn-DBWEL这样的字符串。 module: { loaders: [ // ... { test: /\\.css$/, loader: \"style-loader!css-loader?modules&localIdentName=[path][name]---[local]---[hash:base64:5]\" }, ] } Class的组合 在 CSS Modules中，一个选择器可以继承另一个选择器的规则，这称为“组合”（compositoion）。 .className { background-color: blue; } .title { composes: className; color: red; } 输入其他模块 选择器也可以继承其他CSS文件里面的规则。 .title { composes: className from './another.css'; color: red; } 输入变量 CSS Modules 支持使用变量，不过需要安装 PostCSS 和 postcss-modules-values. 把 post-loader 加入 webpack.config.js. var values = require('postcss-modules-values'); module.exports = { entry: __dirname + '/index.js', output: { publicPath: '/', filename: './bundle.js' }, module: { loaders: [ { test: /\\.jsx?$/, exclude: /node_modules/, loader: 'babel', query: { presets: ['es2015', 'stage-0', 'react'] } }, { test: /\\.css$/, loader: \"style-loader!css-loader?modules!postcss-loader\" }, ] }, postcss: [ values ] }; "},"docs/stylus.html":{"url":"docs/stylus.html","title":"Stylus","keywords":"","body":"Stylus Stylus Try Stylus "},"docs/Stylus-try.html":{"url":"docs/Stylus-try.html","title":"Try Stylus","keywords":"","body":"Try Stylus Nesting selector nesting enables you to keep your styles DRY: body { font: 14px/1.5 Helvetica, arial, sans-serif; #logo { border-radius: 5px; } } body { font: 14px/1.5 Helvetica, arial, sans-serif; } body #logo { border-radius: 5px; } Flexible syntax body font 14px/1.5 Helvetica, arial, sans-serif button button.button input[type='button'] input[type='submit'] border-radius 5px body { font: 14px/1.5 Helvetica, arial, sans-serif; } body button, body button.button, body input[type='button'], body input[type='submit'] { border-radius: 5px; } Parent reference ul li a display: block color: blue padding: 5px html.ie & padding: 6px &:hover color: red ul li a { display: block; color: #00f; padding: 5px; } html.ie ul li a { padding: 6px; } ul li a:hover { color: #f00; } Mixins Transparent mixins Variables Block property access #prompt position: absolute top: 150px left: 50% width: 200px margin-left: -(@width / 2) #prompt { position: absolute; top: 150px; left: 50%; width: 200px; margin-left: -100px; } Robust feature-rich language -pos(type, args) i = 0 position: unquote(type) {args[i]}: args[i + 1] is a 'unit' ? args[i += 1] : 0 {args[i += 1]}: args[i += 1] is a 'unit' ? args[i += 1] : 0 absolute() -pos('absolute', arguments) fixed() -pos('fixed', arguments) #prompt absolut: top 150 left 5px width: 200px margin-left: -(@width / 2) #logo fixed: top left #prompt { position: absolute; top: 150px; left: 5px; width: 200px; margin-left: -100px; } #logo { position: fixed; top: 0; left: 0; } Iteration table for row in 1 2 3 4 5 tr:nth-chihld({row}) height: 10px * row table tr:nth-child(1) { height: 10px; } table tr:nth-child(2) { height: 20px; } ... table tr:nth-child(5) { height: 50px; } Interpolation Operators Type coercion The sprintf operator body foo: '%s / %s' % (5px 10px) foo: 'MS:WeirdStuff(opacity=%s)' % 1 foo: unquote('MS:WeirdStuff(opacity=1)') body { foo: 5px / 10px; foo: MS:WeridStuff(opacity=1); foo: MS:WeirdStuff(opacity=1); } Color operations Functions Keyword arguments Built-in functions Color BIFs "},"docs/Docker.html":{"url":"docs/Docker.html","title":"Docker","keywords":"","body":"Docker 简介 Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口。 一个完整的 Docker 有以下几个部分组成： dockerClient 客户端 Docker Daemon 守护进程 Docker Image 镜像 DockerContainer 容器 1. docker commit 通过 commit 创建容器的一个小缺陷,不能自动执行命令或添加 entrypoint; commit 创建镜像时添加自动运行CMD和entrypoint (-c --change string) 2. 使用默认网络配置启动容器 通过使用网络驱动,docker包含了对容器网络的支持.默认情况下,docker为容器提供了两种网络模式: 桥接(bridge)网络 和 覆盖(overlay)网络 你也可以使用自定义网络驱动插件创建自定义的网络支持,不过这属于高级行为. 3. 管理容器的数据 docker Engine 提供了两种方式管理容器的数据: 数据卷 数据卷容器 数据卷 数据卷是一个或多个容器绕过 Union File System 而指定的一个特殊目录. 数据卷为数据持久化和共享提供了一些有用的功能. 卷在创建容器的时候被初始化.如果容器的基础镜像在卷的挂载点目录中有数据,那么这些数据会哦被复制到初始化后的卷上. 数据卷可以在容器之间共享和复用 数据卷的修改实时生效 更新镜像时不会影响数据卷 即使容器被删除数据卷也会存在 数据卷是为了在容器生命周期内,数据的持久化,独立性而设计的. 因此docker永远不会在删除容器的时候删除数据卷. 也不会将数据卷放入 \"回收站\"而不让容器重新使用. 添加数据卷 在使用 dcoker creaste 或 docker run 命令的时候,使用 -v标识可以为容器添加数据卷.多次使用 -v 可以为容器添加多个数据卷. 4. Dockerfile 指令详解 COPY 复制文件 格式: COPY ... COPY [\"\",... \"\"] ADD 更高级的复制文件 附加 解压等复杂功能 CMD 容器启动命令 CMD 指令的格式和 RUN 相似,也是两种格式: shell 格式:　 CMD exec 格式：CMD [\"可执行文件\", \"参数1\", \"参数2\"...] 参数列表格式：CMD [\"参数1\", \"参数2\"...]。在指定 ENTRYPOINT 指令后，用 CMD 指定具体的参数。 ENTRYPOINT 入口点 ENTRYPOINT 的格式和 RUN指令格式一样, 分为 exec 格式和shell 格式.ENTRYPOINT的目的和 CMD一样,都是在指定容器启动程序及参数.ENTRYPOINT 在运行时也可以替代,不过比CMD要略显繁琐,需要通过 docker run 的参数 --entrypoint 来指定.当指定了 entrypoint 后,CMD 的含义就发生了改变,不再是直接的运行其命令,而是将CMD 的内容作为参数传给 entrypoint 指令, 换句话说实际执行时,将变为:　 \"\" ENV 设置环境变量 格式有两种：　　 ENV ENV = = ARG 构建参数 格式:　ARG [=] VOLUME 定义匿名卷 格式: VOLUME [\"\", \"\"...] VOLUME EXPOSE 声明端口 格式为 EXPOSE [...] WORKDIR 指定工作目录 格式为 WORKDIR USER 指定当前用户 HEALTHCHECK 健康检查 HEALTHCHECK [选项] CMD :　设置检查容器健康状况的命令 HEALTHCHECK NONE:　如果基础镜像有健康检查指令,使用这行可以屏蔽掉其健康检查命令指令 ONBUILD 为他人做嫁衣裳 3. 3. "},"docs/Graphql.html":{"url":"docs/Graphql.html","title":"GraphQL","keywords":"","body":"GraphQL 概念解释 1. Schemaschema 定义了 GraphQL API 系统的类型系统.他完整描述了客户端可以访问的所有数据(对象,成员变量,关系,人很类型).客户端的请求将根据schema进行校验和执行.客户端可以通过\"自省\"(introspection)获取关于schema的信息.schema存放于GraphQL API服务器. 2. Fieldfield是你可以从对象中获取的数据单元。正如GraphQL官方文档所说：“GraphQL查询语言本质上就是从对象中选择field”。关于field，官方标准中还说：所有的GraphQL操作必须指明到最底层的field，并且返回值为标量，以确保响应结果的结构明白无误 标量（scalar）：基本数据类型也就是说，如果你尝试返回一个不是标量的field，schema校验将会抛出错误。你必须添加嵌套的内部field直至所有的field都返回标量。 3. Argumentargument是附加在特定field后面的一组键值对。某些field会要求包含argument。mutation要求输入一个object作为argument。 4. ImplementationGraphQL schema可以使用implement定义对象继承于哪个接口。 5. Connectionconnection让你能在同一个请求中查询关联的对象。通过connection，你只需要一个GraphQL请求就可以完成REST API中多个请求才能做的事。 为帮助理解，可以想象这样一张图：很多点通过线连接。这些点就是node，这些线就是edge。connection定义node之间的关系。 6. Edgeedge表示node之间的connection。当你查询一个connection时，你通过edge到达node。每个edgesfield都有一个nodefield和一个cursorfield。cursor是用来分页的。 7. Nodenode是对象的一个泛型。你可以直接查询一个node，也可以通过connection获取相关node。如果你指明的node不是返回标量，你必须在其中包含内部field直至所有的field都返回标量。 基本使用 1. 发现GraphQL APIGraphQL是可自省的，也就是说你可以通过查询一个GraphQL知道它自己的schema细节。 查询__schema以列出所有该schema中定义的类型，并获取每一个的细节：query { __schema { types { name kind description fields { name } } } } 查询__type以获取任意类型的细节：query { __type(name: \"Repository\") { name kind description fields { name } } } 提示：自省查询可能是你在GraphQL中唯一的GET请求。不管是query还是mutation，如果你要传递请求体，GraphQL请求方式都应该是POST 2. GraphQL 授权要与GraphQL服务器通讯，你需要一个对应权限的OAuth token。 通过命令行创建个人access token的步骤详见这里。你访问所需的权限具体由你请求哪些类型的数据决定。比如，选择User权限以获取用户数据。如果你需要获取版本库信息，选择合适的Repository权限。 当某项资源需要特定权限时，API会通知你的。 3. GraphQL 端点REST API v3有多个端点，GraphQL API v4则只有一个端点： https://api.github.com/graphql 不管你进行什么操作，端点都是保持固定的。 4. GraphQL 通讯在REST中，HTTP动词决定执行何种操作。在GraphQL中，你需要提供一个JSON编码的请求体以告知你要执行query还是mutation，所以HTTP动词为POST。自省查询是一个例外，它只是一个对端点的简单的GET请求。 5. 关于 query 和 mutation 操作在GitHub GraphQL API中有两种操作：query和mutation。将GraphQL类比为REST，query操作类似GET请求，mutation操作类似POST/PATCH/DELETE。mutation mame决定执行哪种改动。 query和mutation具有类似的形式，但有一些重要的不同 6. 关于 queryGraphQL query只会返回你指定的data。为建立一个query，你需要指定“fields within fields\"（或称嵌套内部field）直至你只返回标量。 query的结构类似： query { JSON objects to return } 7. 关于 mutation为建立一个mutation，你必须指定三样东西： mutation name：你想要执行的修改类型 input object：你想要传递给服务器的数据，由input field组成。把它作为argument传递给mutation name payload object：你想要服务器返回给你的数据，由return field组成。把它作为mutation name的body传入 mutation的结构类似： mutation { mutationName(input: {MutationNameInput!}) { MutationNamePayload } 此示例中input object为MutationNameInput，payload object为MutationNamePayload. 8. 使用 variablesvariables使得query更动态更强大，同时他能简化mutation input object的传值。 以下是一个单值variables的示例： query($number_of_repos:Int!) { viewer { name repositories(last: $number_of_repos) { nodes { name } } } } variables { \"number_of_repos\": 3 } 使用variables分为三步： 在操作外通过一个variables对象定义变量：对象必须是有效的JSON。此示例中只有一个简单的Int变量类型，但实际中你可能会定义更复杂的变量类型，比如input object。你也可以定义多个变量。 将变量作为argument传入操作： argument是一个键值对，键是$开头的变量名（比如$number_of_repos），值是类型（比如Int）。如果类型是必须的，添加!。如果你定义了多个变量，将它们以多参数的形式包括进来。 在操作中使用变量： 在此示例中，我们使用变量来代替获取版本库的数量。在第2步中我们指定了类型，因为GraphQL强制使用强类型。 这一过程使得请求参数变得动态。现在我们可以简单的在variables对象中改变值而保持请求的其它部分不变。 用变量作为argument使得你可以动态的更新variables中的值但却不用改变请求。 示例案例 1. query 示例以下query查找octocat/Hellow-World版本库，找到最近关闭的20个issue，并返回每个issue的题目、URL、前5个标签： query { repository(owner:\"octocat\", name:\"Hello-World\") { issues(last:20, states:CLOSED) { edges { node { title url labels(first:5) { edges { node { name } } } } } } } } 让我们一行一行的来看各个部分： query { 因为我们想要从服务器读取而不是修改数据，所以根操作为query。（如果不指定一个操作，默认为query） repository(owner:\"octocat\", name:\"Hello-World\") { 为开始我们的query，我们希望找到repository对象。schema校验指示该对象需要owner和name参数 issues(last:20, states:CLOSED) { 为计算该版本库的所有issue，我们请求issue对象。（我们可以请求某个repository中某个单独的issue，但这要求我们知道我所需返回issue的序号，并作为argument提供。） issue对象的一些细节： 根据文档，该对象类型为IssueConnection schema校验指示该对象需要一个结果的last或first数值作为argument，所以我们提供20 文档还告诉我们该对象接受一个states argument，它是一个IssueState的枚举类型，接受OPEN或CLOSED值。为了只查找关闭的issue，我们给states键一个CLOSED值。 edges { 我们知道issues是一个connection，因为它的类型为IssueConnection。为获取单个issue的数据，我们需要通过edges取得node。 node { 我们从edge的末端获取node。IssueConnection的文档指示IssueConnection类型末端的node是一个issue对象。 既然我们知道了我们要获取一个Issue对象，我们可以查找文档并指定我们想要返回的field： title url labels(first:5) { edges { node { name } } } 我们指定Issue对象的title，url，labels。 labels field类型为LabelConnection。和issue对象一样，由于labels是一个connection，我们必须遍历它的edge以到达连接的node：label对象。在node上，我们可以指定我们想要返回的label对象field，在此例中为name。 你可能注意到了在这个Octocat的公开版本库Hellow-World中运行这个query不会返回很多label。试着在你自己的有label的版本库中运行它，你就会看到差别了。 1. mutation 示例 "},"docs/Inotify.html":{"url":"docs/Inotify.html","title":"Inotify","keywords":"","body":"Inotify 高效、實時的Linux 文件系統事件監控框架 概要 1. 爲什麼需要監控文件系統？人們需要知道在某些文件（夾）上都有哪些變化，比如： 通知配置文件的改變 跟蹤某些關鍵的系統文件的變化 監控某個分區磁盤的整體使用情況 系統崩潰時進行自動清理 自動觸發備份進程 向服務器上傳文件結束時發出通知 通常使用文件輪詢的通知機制，但是這種機制只適用於經常改變的文件（因爲它可以確保每過x秒就可以得到i/o），其他情況下都非常低效，並且有時候會丟失某些類型的變化，例如文件的修改時間沒有改變。像 Tripwire這樣的數據完整性系統，他們基於時間調度來跟蹤文件變化，但是如果想實時監控的變化的話，那麼時間調度就束手無策了。Inotify 就這樣應運而生。 2. Inotify到底是什麼?Inotify是一種文件變化通知機制，Linux內核從2.6.13開始引入。在BSD和Mac OS系統中比較有名的是kqueue，它可以高效的實時跟蹤Linux文件系統的變化。近些年來，以fsnotify 作爲後端，幾乎所有的主流Linux發行版都支持Inotify 機制。如何知道你的Linux 內核是否支持Inotify機制呢 % grep INOTIFY_USER /boot/config-$(uname -r) CONFIG_INOTIFY_USER=y inotifywait -rme modify,attrib,move,close_write,create,delete,delete_self /srv/test 總結 綜上所述，Inotify爲Linux提供了一套高效監控和跟蹤文件變化機制，他可以實時的處理、調試以及監控文件變化，而輪詢是一種延遲機制。對於系統管理員，關於實現事件驅動的服務和系統備份，構建服務以及基於文件操作的程序調試等，inotify無疑提供了強大的支持。 "},"docs/JavaScript.html":{"url":"docs/JavaScript.html","title":"JavaScript","keywords":"","body":"JavaScript 设计模式 "},"docs/JavaScript-designMode.html":{"url":"docs/JavaScript-designMode.html","title":"设计模式","keywords":"","body":"设计模式 设计模式 编码模式 反模式 "},"docs/Nginx.html":{"url":"docs/Nginx.html","title":"Nginx","keywords":"","body":"Nginx nginx 这个轻量级、高性能的 web server 主要可以干两件事： 直接作为http server(代替apache，对PHP需要FastCGI处理器支持)； 另外一个功能就是作为反向代理服务器实现负载均衡； 1.Nginx简介及使用Nginx实现负载均衡的原理1) 环境： 我们本地是Windows系统，然后使用VirutalBox安装一个虚拟的Linux系统。 　　在本地的Windows系统上分别安装nginx(侦听8080端口)和apache(侦听80端口)。在虚拟的Linux系统上安装apache(侦听80端口)。这样我们相当于拥有了1台nginx在前端作为反向代理服务器；后面有2台apache作为应用程序服务器(可以看作是小型的server cluster。;-) )； nginx用来作为反向代理服务器，放置到两台apache之前，作为用户访问的入口； nginx仅仅处理静态页面，动态的页面(php请求)统统都交付给后台的两台apache来处理。　也就是说，可以把我们网站的静态页面或者文件放置到nginx的目录下；动态的页面和数据库访问都保留到后台的apache服务器上。 如下介绍两种方法实现server cluster的负载均衡。 我们假设前端nginx(为127.0.0.1:80)仅仅包含一个静态页面index.html；　后台的两个apache服务器(分别为localhost:80和158.37.70.143:80)，一台根目录放置phpMyAdmin文件夹和test.php(里面测试代码为print “server1“;)，另一台根目录仅仅放置一个test.php(里面测试代码为 print “server2“;)。 2) 针对不同请求 的负载均衡： 在最简单地构建反向代理的时候 (nginx仅仅处理静态不处理动态内容，动态内容交给后台的apache server来处理)，我们具体的设置为：在nginx.conf中修改: 　　location ~ \\.php$ { 　　proxy_pass 158.37.70.143:80 ; 　　} 这样当客户端访问localhost:8080/index.html的时候，前端的nginx会自动进行响应；当用户访问localhost:8080/test.php的时候(这个时候nginx目录下根本就没有该文件)，但是通过上面的设置 location ~ .php$(表示正则表达式匹配以.php结尾的文件，详情参看location是如何定义和匹配的http://wiki.nginx.org/NginxHttpCoreModule) ，nginx服务器会自动pass给 158.37.70.143的apache服务器了。该服务器下的test.php就会被自动解析，然后将html的结果页面返回给nginx，然后 nginx进行显示(如果nginx使用memcached模块或者squid还可以支持缓存)，输出结果为打印server2。如上是最为简单的使用nginx做为反向代理服务器的例子； 们现在对如上例子进行扩展，使其支持如上的两台服务器。我们设置nginx.conf的server模块部分，将对应部分修改为： 　　location ^~ /phpMyAdmin/ { 　　proxy_pass 127.0.0.1:80 ; 　　} 　　location ~ \\.php$ { 　　proxy_pass 158.37.70.143:80 ; 　　} 上面第一个部分location ^~ /phpMyAdmin/，表示不使用正则表达式匹配(^~)，而是直接匹配，也就是如果客户端访问的 URL是以http://localhost:8080/phpMyAdmin/ 开头的话(本地的nginx目录下根本没有phpMyAdmin目录)，nginx会自动pass到127.0.0.1:80 的Apache服务器，该服务器对phpMyAdmin目录下的页面进行解析，然后将结果发送给nginx，后者显示；如果客户端访问URL是http://localhost/test.php 的话，则会被pass到158.37.70.143:80 的apache进行处理。 　　因此综上，我们实现了针对不同请求的负载均衡。　　〉如果用户访问静态页面index.html，最前端的nginx直接进行响应； 　　〉如果用户访问test.php页面的话，158.37.70.143:80 的Apache进行响应； 　　〉如果用户访问目录phpMyAdmin下的页面的话，127.0.0.1:80 的Apache进行响应； 3) 访问同一页面 的负载均衡：即用户访问http://localhost:8080/test.php 这个同一页面的时候，我们实现两台服务器的负载均衡 (实际情况中，这两个服务器上的数据要求同步一致，这里我们分别定义了打印server1和server2是为了进行辨认区别)。 现在我们的情况是在windows下nginx是localhost侦听8080端口；　　两台apache，一台是127.0.0.1:80(包含test.php页面但是打印server1)，另一台是虚拟机的158.37.70.143:80(包含test.php页面但是打印server2)。 因此重新配置nginx.conf为： 首先在nginx的配置文件nginx.conf的http模块中添加，服务器集群server cluster(我们这里是两台)的定义： 复制代码 代码如下: upstream myCluster { 　　server 127.0.0.1:80 ; 　　server 158.37.70.143:80 ; 　　} 表示这个server cluster包含2台服务器，然后在server模块中定义，负载均衡：复制代码 代码如下: 　　location ~ \\.php$ { 　　proxy_pass http://myCluster ; #这里的名字和上面的cluster的名字相同 　　proxy_redirect off; 　　proxy_set_header Host $host; 　　proxy_set_header X-Real-IP $remote_addr; 　　proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 　　} 这样的话，如果访问http://localhost:8080/test.php 页面的话，nginx目录下根本没有该文件，但是它会自动将pass到myCluster定义的服务区机群中，分别由127.0.0.1:80;或者158.37.70.143:80;来做处理。上面在定义upstream的时候每个server之后没有定义权重，表示两者均衡；如果希望某个更多响应的话例如：复制代码 代码如下: 　　upstream myCluster { 　　server 127.0.0.1:80 weight=5; 　　server 158.37.70.143:80 ; 　　} 这样表示5/6的几率访问第一个server,1/6访问第二个。另外还可以定义max_fails和fail_timeout等参数。综上，我们使用nginx的反向代理服务器reverse proxy server的功能，将其布置到多台apache server的前端。nginx仅仅用来处理静态页面响应和动态请求的代理pass，后台的apache server作为app server来对前台pass过来的动态页面进行处理并返回给nginx。通过以上的架构，我们可以实现nginx和多台apache构成的机群cluster的负载均衡。 两种均衡： 可以在nginx中定义访问不同的内容，代理到不同的后台server； 如上例子中的访问phpMyAdmin目录代理到第一台server上；访问test.php代理到第二台server上； 可以在nginx中定义访问同一页面，均衡 (当然如果服务器性能不同可以定义权重来均衡)地代理到不同的后台server上。 如上的例子访问test.php页面，会均衡地代理到server1或者server2上。实际应用中，server1和server2上分别保留相同的app程序和数据，需要考虑两者的数据同步 "},"docs/NginxInstall.html":{"url":"docs/NginxInstall.html","title":"Nginx原理、安装预配置","keywords":"","body":"Nginx原理、安装预配置 1. Nginx的模块与工作原理 Nginx由内核和模块组成。内核十分简洁,因此完成的工作相对简单.内核的主要工作就是通过查找配置文件将客户端请求映射到一个location block(location是Nginx配置中的一个指令,用于URI/URL匹配)，而在这个location中所配置的每个指令将会启动不同的模块去完成相应的工作.1.1 Nginx的模块结构 核心模块:包括：http模块,event模块和mail模块 基础模块:包括HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy模块和 HTTP Rewrite 模块 第三方模:包括HTTP Upstream Request Hash 模块、Notice 模块 以及HTTP Access Key 模块属于第三方模块,用户根据自己的需要开发的模块都属于第三方模块。 Nginx 的模块从功能上分为三类： Handlers(处理器模块)此类模块直接处理请求,并进行输出内容和修改 headers信息等操作。handlers 处理器模块一般只能有一个。 Filters (过滤器模块)此类模块主要对其他处理器模块输出的内容进行修改操作,最后由 Nginx 输出。 Proxies (代理类模块)就是 Nginx 的 HTTP Upstream 之类的模块,这些模块主要与后端一些服务比如 fastcgi 等操作交互,实现服务代理和负载均衡等功能。 下图展示了 Nginx 的模块处理一次常规的 HTTP 请求和响应的过程： 2. Nginx的模块与工作原理 "},"docs/Node.html":{"url":"docs/Node.html","title":"NodeJS","keywords":"","body":"NodeJS Assert 断言 chai.js 断言库 Node Global Obj And Var CLI Writed By Nodejs Framework Hapi Js Framework Electrode Electrode Platform Electrode Question Redux Redux Basic Usage Middleware And Asynchronous React-Redux 的用法 NPM Package semver "},"docs/Node-assert.html":{"url":"docs/Node-assert.html","title":"Assert 断言","keywords":"","body":"Node assert 断言 assert 模块提供了断言测试的函数，用于测试不变式。 assert(value[,message])assert.ok()的别名。 assert.deepEqual(actual, expected[, message])测试 actual 参数与 expected 参数是否深度相等。原始值使用相等运算符 (==) 比较。 只测试可枚举的自身属性，不测试对象的原型、连接符、或不可枚举的属性(这些情况使用 assert.deepStrictEqual())。 // 不会跑出 AssertionError，因为 RegExp 对象的属性不是可枚举的 assert.deepEqual(/a/gi, new Date()); Map 和 Set 包含的自相也会被测试。 子对象中可枚举的自身属性也会被测试： const assert = require('assert'); const obj1 = { a: { b: 1 } }; const obj2 = { a: { b: 2 } }; const obj3 = { a: { b: 1 } }; const obj4 = Object.create(obj1); assert.deepEqual(obj1, obj1); // 测试通过，对象与自身相等。 assert.deepEqual(obj1, obj2); // 抛出 AssertionError: { a: { b: 1 } } deepEqual { a: { b: 2 } } // 因为 b 属性的值不同。 assert.deepEqual(obj1, obj3); // 测试通过，两个对象相等。 assert.deepEqual(obj1, obj4); // 抛出 AssertionError: { a: { b: 1 } } deepEqual {} // 因为不测试原型。 如果两个值不相等，则抛出一个带有 message 属性的 AssertionError，其中 message 属性的值等于传入的 message 参数的值。 如果 message 参数为 undefined，则赋予默认的错误信息。 assert.deepStrictEqual(actual, expected[, message]) 与 assert.deepEqual() 大致相同，但是有一些区别： 原始值使用 全等运算符（===）比较。 Set 的值与 Map 的键使用 SameValueZero 比较。 对象的原型也是用全等运算符 比较 对象的类型标签要求相同 Object wrappers are compared both as objects and unwrapped values. const assert = require('assert'); assert.deepEqual({ a: 1 }, { a: '1' }); // 测试通过，因为 1 == '1'。 assert.deepStrictEqual({ a: 1 }, { a: '1' }); // 抛出 AssertionError: { a: 1 } deepStrictEqual { a: '1' } // 因为使用全等运算符 1 !== '1'。 // 以下对象都没有自身属性。 const date = new Date(); const object = {}; const fakeDate = {}; Object.setPrototypeOf(fakeDate, Date.prototype); assert.deepEqual(object, fakeDate); // 测试通过，不测试原型。 assert.deepStrictEqual(object, fakeDate); // 抛出 AssertionError: {} deepStrictEqual Date {} // 因为原型不同。 assert.deepEqual(date, fakeDate); // 测试通过，不测试类型标签。 assert.deepStrictEqual(date, fakeDate); // 抛出 AssertionError: 2017-03-11T14:25:31.849Z deepStrictEqual Date {} // 因为类型标签不同。 assert.deepStrictEqual(new Number(1), new Number(2)); // Fails because the wrapped number is unwrapped and compared as well. assert.deepStrictEqual(new String('foo'), Object('foo')); // OK because the object and the string are identical when unwrapped. 如果两个值不相等，则抛出一个带有 message 属性的 AssertionError，其中 message 属性的值等于传入的 message 参数的值。 如果 message 参数为 undefined，则赋予默认的错误信息。 assert.doesNotThrow(block[, error][, message]) 断言 block 函数不会抛出错误。当 assert.doesNotThrow() 被调用时，他会立即调用 block 函数。如果抛出错误且错误类型与 error 参数指定的相同，则抛出 AssertionError。 如果错误类型不相同，或 error 参数为 undefined， 则抛出错误。 assert.fail(actual, expected[, message[, operator[,stackStartFunction]]]) 抛出 AssertionError assert.ifError(value)如果 value 为真，则抛出 value。 可用于测试回调函数的 error 参数 assert.notDeepEqual(actual, expected[, message]) assert.ok(value[, message]) assert.throws(block[, error][, message])断言 block 函数会抛出错误 注意事项 对于 SameValueZero 比较， 建议使用 ES2015 的 Object.is(); "},"docs/Chai.html":{"url":"docs/Chai.html","title":"chai.js 断言库","keywords":"","body":"chai.js 断言库 BDD风格的expect/should API，TDD 风格的Assert API BDD expect 和 should 是 BDD 风格的，二者使用相同的链式语言来组织断言，但不同于他们初始化断言的方式：expect 使用构造函数来创建断言对象实例，而should通过为Object.protorype新增方法来实现断言（所以should 不支持 IE）；expect 直接指向 chai.expect ,而 should 则是chai.should(). 语言链 to be been is that which and has have with at of same .not 对之后的断言取反 expect(foo).to.not.equal('bar'); expect(goodFn).to.not.throw(Error); expect({ foo: 'baz' }).to.have.property('foo').and.not.equal('bar'); .deep "},"docs/Node-global.html":{"url":"docs/Node-global.html","title":"Node Global Obj And Var","keywords":"","body":"NODEJS Node.js 的全局对象和全局变量 全局对象 global: 表示 Node 所在的全局环境，类似于浏览器中的 window 对象。 process: 指向 Node 内置的 process模块，允许开发者与当前进程互动。(process.exit()); console: 指向 Node 内置的 console 模块，提供命令行环境中的标准、标准输出环境。(console.log()) 全局函数 定时器函数: setTimeout(), clearTimeout(), setInterval(), clearInterval(). require: 用于加载模块。 全局变量 __filename: 指向当前运行的脚本文件名。 __dirname: 指向当前运行的脚本所在的目录。 准全局变量 模块内部的局部变量，指向的对象根据模块不同而不同，但是所有模块都适用，可以看作是伪全局变量，主要为 module, module.exports , exports 等。 module 变量指代当前模块。module.exports变量表示当前模块对外输出的接口，其他文件加载该模块，实际上就是读取module.exports变量。 module.id 模块的识别符，通常是模块的文件名。 module.filename 模块的文件名。 module.loaded 返回一个布尔值，表示模块是否已经完成加载。 module.parent 返回使用该模块的模块。 module.children 返回一个数组，表示该模块要用到的其他模块。 这里需要特别指出的是，exports变量实际上是一个指向 module.exports 对象的链接，等同在每个模块头部，有一行这样的命令。 var exports = module.exports; 这造成的结果是，在对外输出模块接口时，可以向exports对象添加方法，但是不能直接将exports变量指向一个函数： exports = function (x){ console.log(x);}; 上面这样的写法是无效的，因为它切断了exports与module.exports之间的链接。但是，下面这样写是可以的。 exports.area = function (r) { return Math.PI * r * r; }; exports.circumference = function (r) { return 2 * Math.PI * r; }; "},"docs/CLI.node.html":{"url":"docs/CLI.node.html","title":"CLI Writed By Nodejs","keywords":"","body":"Node.js 编写CLI Node.js 的应用场景有前后端分离、海量web页面渲染服务、命令行工具和桌面端应用等等。 Why Node.js npm OS 无关的包管理机制 npm 完善的生态系统 对JavaScript 更加熟悉 npm关联CLI的基本原理 在package.json里面增加一个bin字段。模块发布到npm上后，开发者安装这个包的时候会检查是否有bin字段，如果有bin字段则会使用软链接的方式创建可以全局使用的命令。 如果模块采用全局安装的方式，对于类unix系统，会在/usr/local/bin目录创建软链接，对于windows系统，在`C:\\Users\\username\\AppData\\Roaming\\npm目录创建软链接。 如果模块采用局部安装的方式，则会在项目内的./node_modules/.bin目录创建软链接。配置好的package.json如下: \"description\": \"A command line tool aims to improve front-end engineer workflow.\", \"main\": \"lib/index.js\", \"bin\" : { \"feflow\" : \"./bin/feflow\" } Feflow的技术架构 Feflow总体分为3个模块，包括parser命令行参数解析、核心命令以及插件机制。【链接】 扫描器的实现 插件机制设计 feflow install #安装一个插件，--force则会强制安装 feflow remove #卸载一个插件 feflow list #列举所有插件信息 feflow list #列举某个插件信息 插件机制实现 插件机制的实现包括两个部分：插件注册机制和插件发现机制。 feflow要求插件必须以feflow-plugin-开头或者generator-开头，generator作为一种特殊的插件，插件代码以npm包的形式存储和管理。运行feflow install plugin命令时，会通过npm的register检查是否存在插件，如果存在，会检查当前插件是否是最新版本。如果不是最新版本，则会提示用户是否需要更新。然后将插件下载到Home目录下的.feflow目录（windows系统为C:\\Users\\username\\.feflow目录）下的node_modules里面，并且写入到配置文件里面。 本地模块注册机制 本地模块发现机制 常用第三方包分享 osenv 方便获取不同系统的环境和目录配置 figlet 命令行炫酷的Logo生成器 meow 命令封装 inquire 强大的用户交互 chalk 让命令行的output带有颜色 easytable 表格信息展示，用于升级包的提示 minimlist 用户输入的参数解析 shelljs Node.js执行shell命令 clui 进度条 遇到问题 windows下用户未设置HOME环境变量导致报错解决办法: 由于windows下HOME环境变量并非默认存在，因此不能直接使用。判断process.platform === ‘win32'，优先使用HOME变量，否则使用USERPROFILE变量；建议使用osenv这个包。 OSX平台运行feflow报错: env: node\\r: No such file or directory解决办法: 由于类unix系统的换行符号为\\n，而windows系统为\\n\\r。修复换行问题。可以在工程根目录下加.gitattributes文件，设置* text eol=lf，这样git提交时就不会讲LF转换成CRLF "},"docs/framework.html":{"url":"docs/framework.html","title":"Framework","keywords":"","body":"Framework Framework Hapi Js Framework "},"docs/framework-Hapi.html":{"url":"docs/framework-Hapi.html","title":"Hapi Js Framework","keywords":"","body":"Hapi Js Framework "},"docs/Electrode.html":{"url":"docs/Electrode.html","title":"Electrode","keywords":"","body":"Electrode Electrode Electrode Platform Electrode Question NodeJS Node Global Obj And Var Assert 断言 Framework Hapi Js Framework "},"docs/Electrode-platform.html":{"url":"docs/Electrode-platform.html","title":"Electrode Platform","keywords":"","body":"Electrode precondition：universal React/Node.js application What is Electrode Electrode is a platform for building large scale Universal React web applications with a standardized structure that follows best practices and has modern technologies baked in. Electrode focuses on performance, component reusability, and simple deployment to multiple cloud providers—so you can focus on what makes your app unique. Why use Electrode If you're writing a universal React/Node.js application, then Electrode is for you! Universal JavaScriptfocus on Universal JavaScript SEO Reusability Maintainability Code/UI Reuse Server Side Rendering(SSR) Performance Fast Startup and Deployment Three Pillars Requirements What are Archetypes Archetypes are npm modules that contain the typical standard stuff you would have to add to every new project you create. They encapsulate boilerplates for centralizing your project configurations, workflows, and dependencies. Stand alone Modules Confippet Above The Fold Rendering Server Side Render Caching + Profiling Stateless CSRF Validation Redux Router Engine Powerful Electrode Tools Electrify Electrode Explorer Bundle Analyzer Electrode 提供了什么 一个易用的工作流，从而更加专注于代码，而不是环境。 Alone Modules Functionality Powerful Electrode Tools Node Framework electrode-server hapi已配置为中心，配置优于编码，业务逻辑和传输层进行分离；内置用于构建waeb和service应用的庞大的插件(验证、鉴权、和其他基础设施) express Lerna Lerna 是用来优化托管在git\\npm上的多package代码库的工作流的一个管理工具，可以让你在主项目下管理多个子项目，从而解决了多个包相互依赖，且发布时需要手动维护多个包的问题。 前端 React semantic-ui-react redux(flux的实现) react-router ... 同时使用react 的controler-view模式，只用来保存状态，然后将其转发给子组件。一定程度上提高component view 层的重用性。 xenv-configwebpack-config-composer "},"docs/Electrode-question.html":{"url":"docs/Electrode-question.html","title":"Electrode Question","keywords":"","body":"Electrode Question css Modules 編譯問題 .css 後綴會使用css modules；而 .styl 後綴使用 stylus；因而考慮倘若使用了 semantic等 UI 庫時選擇 .styl（前提是外部加載UI庫css文件） "},"docs/redux.html":{"url":"docs/redux.html","title":"Redux","keywords":"","body":"Redux Redux Redux Basic Usage Middleware And Asynchronous React-Redux 的用法 "},"docs/Redux-basic.html":{"url":"docs/Redux-basic.html","title":"Redux Basic Usage","keywords":"","body":"Redux 基本用法 React 只是 DOM 的一个抽象层，并不是 Web 应用的完整解决方案。他没有涉及 代码结构 和 组件之间的通信。对于大型的复杂应用来说，这两方面恰恰是最关键的。因此，只用 React 没法写大型应用。为了解决这个问题，2014年 Facebook 提出了 Flux 架构的概念，已发了很多的实现。2015年， Redux 出现，将 Flux 与函数式编程结合在一起，很短时间内就成为了最热门的前端架构。 首先明确一点， Redux 是一个很有用的架构，但不是费用不可。事实上，大多数情况，你可以不用它，只用 React 就够了。 以下这些情况不需要使用 Redux： 用户的使用方式非常简单 用户之间没有协作 不需要与服务器大量交互，也没有使用 WebSocket 视图层 （View）只从单一来源获取数据 以下这些情况是 Redux 的适用场景：多交互、多数据源。 用户的使用方式复杂 不同身份的用户有不同的使用方式（比如普通用户和管理员） 多个用户之间可以协作 与服务器大量交互，或者使用了 WebSocket View 要从多个来源获取数据 从组件角度出发，如果你的应用有以下场景，可以考虑使用 Redux。 某个组件的状态，需要共享 某个状态需要在任何地方都可以拿到 一个组件需要改变全局状态 一个组件需要改变另一个组件的状态 预备知识 Redux 文档Redux 视频前30，后30 设计思想 Web 应用是一个状态机，视图与状态是一一对应的。 所有的状体，保存在一个对象里面。 基本概念和 API Store Store 就是数据保存的地方，你可以把它看成一个容器。整个应用只能有一个 Store。 Redux 提供 createStore 这个函数，用来生成 Store。 import { createStore } from 'redux'; const store = createStore(fn); // createStore 函数接收另一个函数作为参数，返回新生成的 Store 对象 State Store 对象班含所有数据。如果想得到某个时点的数据，就要对 Store 生成快照。这种时点的数据集合，就叫做 State。 import { createStore } from 'redux'; const store = createStore(fn); const state = store.getState(); // 当前时刻的 State ，可以通过 store.getState() 拿到 Redux 规定，一个 State 对应一个 View。只要 State 相同， View 就相同。你知道 State，就知道 View 是什么样，反之亦然。 Action State 的变化，会导致 View 的变化。但是，用户接触不到 State， 所有 State 的变化必须是 View 导致的。Action 就是 View 发出的通知，表示 State 应该要发生变化了。 Action Creator View 要发送多少种消息，就会有多少种 Action。如果都手写，会很麻烦。可以定义一个函数来生成 Action,这个函数就叫 Action Creator。 const ADD_TODO = '添加 TODO'; function addTodo(text) { return { type: ADD_TODO, text } } const action = addTodo('Learn Redux'); // addTodo 函数就是一个 Action Creator store.dispatch Store.dispatch() 是 View 发出 Action 的唯一方法。 import { createStore } from 'redux'; const store = createStore(fn); store.dispatch({ type: 'ADD_TODO', payload: 'Learn Redux' }); // store.dispatch 接收一个 Action 对象作为参数，将它发送出去 // 结合 Action Creator，改写代码 store.dispatch(addTodo('Learn Redux')); Reduxcer Store 收到 Action 以后，必须给出一个新的 State，这样 View 才会发生变化。这种 State 的计算过程就叫做 Reducer。Reducer 是一个函数它接收 Action 和当前 State 作为参数，返回一个新的 State。 const reducer = function (state, action) { // ... return new_state; } 整个应用的初始状态，可以作为 State 的默认值。 const defaultState = 0; const reducer = (state = defaultState, action) => { switch (action.type) { case 'ADD': return state + action.payload; default: return state; } }; const state = reducer(1, { type: 'ADD', payload: 2 }); 实际应用中， Reducer 函数不用像上面这样手动调用，store.dispatch 方法会触发 Reducer 的自动执行。为此， Store 需要知道 Reducer 函数，做法就是在生成 Store 的时候，将 Reducer 传入 createStore 方法。 import { createStore } from 'redux'; const store = createStore(reducer); 为什么这个函数叫做 Reducer 呢？因为他可以作为数组的 reduce 方法的参数。请看下面的例子，一系列 Action 对象按照顺序作为一个数组。 const actions = [ {type: 'ADD', payload: 0}, {type: 'ADD', payload: 1}, {type: 'ADD', payload: 2}, ]; const total = actions.reduce(reducer, 0);// 3 纯函数 Reducer 函数最重要的特征是，他是一个纯函数。也就是说，只要是同样的输入，必定得到同样的输出。春函数是函数式编程，必须遵守以下一些约束。 不得改写参数 不能调用系统 I/O 的 API 不能调用 Date.now() 或者 Math.random() 等不纯的方法，因为每次会得到不一样的结果 Reducer 函数里面不能改变 State，必须返回一个全新的对象，请参考下面的写法： // State 是一个对象 function reducer(state, action) { return Object.assign({}, state, { thingToChange }); // 或者 return { ...state, ...newState }; } // State 是一个数组 function reducer(state, action) { return [...state, newItem]; } 某个 View 对应的 State 总是一个不变的对象。 store.subscribe() Store 允许使用 store.subscribe 方法设置监听函数，一旦 State 发生变化，就自动执行这个函数。 import { createStore } from 'redux'; const store = createStore(reducer); store.subscribe(listener); 解除监听：store.subscribe 方法返回一个函数，调用这个函数就可以解除监听了。 Store的实现 let store = createStore(todoApp, window.STATE_FROM_SERVER); // window.STATE_FROM_SERVER就是整个应用的状态初始值。注意，如果提供了这个参数，他会覆盖 Reducer 函数的默认初始值。 下面是 createStore 方法的一个简单实现，可以了解一下 Store 是怎么生成的。 const createStore = (reducer) => { let state; let listeners = []; const getState = () => state; const dispatch = (action) => { state = reducer(state, action); listeners.forEach(listener => listener()); }; const suvscribe = (listener) => { listeners.push(listener); return () => { listeners = listeners.filter(l => l !== listener); } }; dispatch({}); return { getState, dispatch, subscribe }; }; Reducer 的拆分 combineReducer 的简单实现： const combineReducers = reducers => { return (state = {}, action) => { return Object.keys(Reducers).reduce( (nextState, key) => { nextState[key] = reducers[key](state[key], action); return nextState; } ); } }; "},"docs/Redux-middleware.html":{"url":"docs/Redux-middleware.html","title":"Middleware And Asynchronous","keywords":"","body":"Redux 中间件与异步操作 Reducer：纯函数，只承担计算 State 的功能，不合适承担其他功能，也承担不了，因为理论上，纯函数不能进行读写操作。 View：与 State 一一对应，可以看作 State 的视觉层，也不合适承担其他功能。 Action：存放数据的对象，即消息的载体，只能被别人操作，自己不能进行任何操作。 中间件的用法 import { applyMiddlerware, createStore } from 'redux'; import createLogger from 'redux-logger'; const logger = creteLogger(); const store = createStore( reducer, applyMiddleware(logger) ); 注意： createStore 方法可以接受整个应用的初始状态作为参数，那样的话， applyMiddleware 就是第三个参数了。 中间件的次序有讲究。 applyMiddlewares() export default function applyMiddleware(...middlewares) { return (createStore) => (reducer, preloadedState, enhancer) => { var store = createStore(reducer, preloadedState, enhancer); var dispatch = store.dispatch; var chain = []; var middlewareAPI = { getState: store.getState, dispatch: (action) => dispatch(action) }; chain = middlewares.map(middleware => middleware(middlerwareAPI)); dispatch = compose(...chain)(store.dispatch); return { ...store, dispatch } } } 所有中间件被放进了一个数组chain，然后嵌套执行，最后执行store.dispatch。可以看到，中间件内部（middlewareAPI）可以拿到getState和dispatch这两个方法。 异步操作的基本思路 redux-thunk redux-promise "},"docs/React-Redux.html":{"url":"docs/React-Redux.html","title":"React-Redux 的用法","keywords":"","body":"Redux React-Redux 的用法 UI组件 只负责 UI 的呈现，不带有任何业务逻辑 没有状态（即不使用this.state这个变量） 所有数据都由参数（this.props）提供 不使用任何 Redux 的 API 容器组件 负责管理数据和业务逻辑，不负责 UI 的呈现 带有内部状态 使用 Redux 的 API connect() React-Redux 提供 connect 方法， 用于从 UI 组件生成容器组件。 connect 的意思，就是将这两种组件连起来。 import { connect } from 'react-redux'; const VisibleTodoList = connect()(TodoList); 为了定义业务逻辑需要给出下面的信息： 输入逻辑：外部的数据（即state对象）如何转换为 UI 组件的参数 输出逻辑：用户发出的动作如何变为 Action 对象，从 UI 组件传出去。 因此， connect 方法的完整 API 如下： import { connect } from 'react-redux'; const VisibleTodoList = connect( mapStateToProps, mapDispatchToProps )(TodoList); connect 方法接受两个参数： mapStateToProps 和mapDispatchToProps 。它们定义了 UI 组件的业务逻辑。前者负责输入逻辑，即将state映射到 UI 组件的参数（props），后者负责输出逻辑，即将用户对 UI 组件的操作映射成 Action。 Provider 组件 "},"docs/npm.html":{"url":"docs/npm.html","title":"NPM Package","keywords":"","body":"NPM Package NPM Package semver "},"docs/npm-semver.html":{"url":"docs/npm-semver.html","title":"semver","keywords":"","body":"semver 語義化版本（Semantic Versioning）規範的一個實現，實現了版本和版本範圍的解析、計算、比較。 semver 定義了兩種概念： 版本是指例如0.4.1、1.2.7、1.2.4-beta.0 這樣表示包的特定版本的字符串。 範圍則是對滿足特定規則的版本的一種表示，例如 1.2.3-2.3.4、1.x、^0.2、>1.4。 用semver 去比較版本將會是一個很好的選擇： plugin.forEach(function () { if (!semver.satisfies(platformVersion, plugin.engines.platform)) { console.log(plugin.name, 'require', plugin.engines.platform, 'but unable to meet'); } }) 在你使用express 設計一個支持多版本的API服務器時，你可以這樣做： app.get('/', appVersion(' 選擇semver 的禮由很簡單， 讓裝專業的包去完成專業的工作 "},"docs/Process.html":{"url":"docs/Process.html","title":"Process","keywords":"","body":"进程, 线程 1. 进程和线程的区别 简而言之,一个程序至少有一个进程,一个进程至少有一个线程.线程的划分尺度小于进程，使得多线程程序的并发性高。另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位. 线程是进程的一个实体,是CPU调度和分派的基本单位,他是比进程更小的独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源. 一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行. 主要差别: 进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。如果有兴趣深入的话，我建议你们看看《现代操作系统》或者《操作系统的设计与实现》。对就个问题说得比较清楚。 2. 简介 进程（process）是一块包含了某些资源的内存区域。操作系统利用进程把它的工作划分为一些功能单元。 进程 中所包含的一个或多个执行单元称为线程（thread）。进程还拥有一个私有的虚拟地址空间，该空间仅能被它所包含的线程访问。 当运行.NET程序时，进程还会把被称为CLR的软件层包含到它的内存空间中。上一章曾经对CLR做了详细描述。该软件层是在进程创建期间由运行时宿主载入的（参见4.2.3节）。 线程只能归属于一个进程并且它只能访问该进程所拥有的资源。当操作系统创建一个进程后，该进程会自动申请一个名为主线程或首要线程的线程。主线程将执行运行时宿主, 而运行时宿主会负责载入CLR。 应用程序（application）是由 一个或多个相互协作的进程组成的。例如，Visual Studio开发环境就是利用一个进程编辑源文件，并利用另一个进程完成编译工作的应用程序。 在Windows NT/2000/XP操作系统下，我们可以通过任务管理器在任意时间查看所有的应用程序和进程。尽管只打开了几个应用程序，但是通常情况下将有大约30个进程同时运行。 事实上，为了管理当前的会话和任务栏以及其他一些任务，系统执行了大量的进程。 3. 进程3.1 简介 在运行于32位处理器上的32位Windows操作系统中，可将一个进程视为一段大小为4GB（232字节）的线性内存空间，它起始于0x00000000结束于0xFFFFFFFF。这段内存空间不能被其他进程所访问，所以称为该进程的私有空间。这段空间被平分为两块，2GB被系统所有，剩下2GB被用户所有。 如果有N个进程运行在同一台机器上，那么将需要N×4GB的海量RAM，还好事实并非如此。 Windows是按需为每个进程分配内存的，4GB是32位系统中一个进程所占空间的上限。将进程所需的内存划分为4KB大小的内存页，并根据使用情况将这些内存页存储在硬盘上或加载到RAM中，通过系统的这种虚拟内存机制，我们可以有效地减少对实际内存的需求量。当然这些对用户和开发者来说都是透明的。 3.2 System.Diagnostics.Process 类System.Diagnostics.Process类的实例可以引用一个进程，被引用的进程包含以下几种。 该实例的当前进程。 本机上除了当前进程的其他进程。 远程机器上的某个进程。 通过该类所包含的方法和字段，可以创建或销毁一个进程，并且可以获得一个进程的相关信息。下面将讨论一些使用该类实现的常见任务。默认情况下，子进程将继承其父进程的安全上下文。但还可以使用Process.Start()方法的一个重载版本在任意用户的安全上下文中启动该子进程，当然需要通过一个System.Diagnostics. ProcessStartInfo类的实例来提供该用户的用户名和密码 3.3 避免在一台机器上同时运行同一应用程序的多个实例 有些应用程序需要这种功能。实际上，通常来说在同一台机器上同时运行一个应用程序的多个实例并没有意义。 直到现在，为了在Windows下满足上述约束，开发者最常用的方法仍然是使用有名互斥体（named mutex）技术（参见5.7.2节）。然而采用这种技术来满足上述约束存在以下缺点： 该技术具有使互斥体的名字被其他应用程序所使用的较小的、潜在的风险。在这种情况下该技术将不再有效并且会造成很难检测到的bug。 该技术不能解决我们仅允许一个应用程序产生N个实例这种一般的问题。 幸而在System.Diagnostics.Process类中拥有GetCurrentProcess()（返回当前进程）和 GetProcesses()（返回机器上所有的进程）这样的静态方法. 4. 线程4.1 简介 一个线程包含以下内容: 一个指向当前被执行指令的指令指针； 一个栈； 一个寄存器值的集合，定义了一部分描述正在执行线程的处理器状态的值； 一个私有的数据区。 所有这些元素都归于线程执行上下文的名下。处在同一个进程中的所有线程都可以访问该进程所包含的地址空间，当然也包含存储在该空间中的所有资源。 4.2 受托管的线程与 Windows线程 4.3 抢占式多任务处理 4.3 进程与线程的优先级 进程,线程 操作系统的设计，因此可以归结为三点： 以多进程形式，允许多个任务同时运行； 以多线程形式，允许单个任务分成不同的部分运行； 提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源。 进程状态：进程有三个状态，就绪，运行和阻塞。 "},"docs/Node-sync.html":{"url":"docs/Node-sync.html","title":"阻塞与非阻塞","keywords":"","body":"阻塞与非阻塞 怎麼理解阻塞和非阻塞的區別？ 1. 同步和異步　　 同步和異步關注的是消息通信機制( synchronous communication/ asynchronous communication)所謂同步，就是在發出一個調用時，在沒有得到結果之前，該-調用-就不返回。但是一旦調用返回，就得得到返回值了。　　 換句話說，就是由-調用者-主動等待這個-調用-結果。　　 而異步則是相反，-調用-在發出之後，這個調用就直接得到結果。而是在-調用-發出後，-換句話說-當一個異步過程調用發出後，調用者不會立即得到結果。而是在-調用-發出後，-被調用者-通過狀態、通知來通知調用者，或通過灰調函數處理這個調用。　　 典型的異步編程比如Node.js 2. 阻塞和非阻塞阻塞和非阻塞關注的是程序在等待調用結果(消息，返回值)是的狀態。阻塞調用是指調用結果返回之前，但錢線程會被掛起。調用線程指頭在得到結果之後才會返回。非阻塞調用指在不能立刻得到結果之前，該調用不會阻塞當前線程。 　 阻塞與非阻塞、同步與異步I/O模型 　I/O 模型： 1. Linux 下的五中I/O模型 阻塞I/O 非阻塞I/O I/O 復用 信號驅動I/O 異步I/O 前四種都是同步，只有最後一種才是異步IO； 2. Windows 的異步I/O模型有下面六種 select選擇模型 WSAAsyncSelect 異步選擇模型 WSAEventSelect 事件選擇模型 Overlapped I/O 事件通知模型 Overlapped I/O 完成例程模型 IOCP 模型 Linux 的幾種I/O 模型介紹： 1. 阻塞I/O模型 進程會一直阻塞,直到數據拷貝完成應用程序調用一個I/O函數,導致應用程序阻塞,等待數據準備好.如果數據沒有準備好,一直等待...數據準備好了,從內核拷貝到用戶空間,I/O函數返回成功指示. 可能阻塞套接字的Windows Sockets API調用分爲以下四種: 輸入操作:recv(),recvfrom(),WSARecv() 和 WSARecvfrom() 函數. 以阻塞套接字爲參數調用該函數接收數據.如果此時套接字緩衝區內沒有數據刻度,則調用線程在數據到來前一直睡覺. 輸出操作:send(), sendto(), WSASend() 和 WSASendto() 函數.以阻塞套接字爲參數調用該函數發送數據.如果套接字緩衝區沒有可用空間,縣城會一直睡覺,直到有空間. 接受連接:accept() 和 WSAAccept() 函數.以阻塞套接字爲參數調用該函數,等待接受對方的連接請求.如果此時沒有連接請求,線程就會進入睡眠狀態. 外出連接:connect() 和 WSAConnect() 函數. 對於TCP鏈接,客戶端以阻塞套接字爲參數,調用該函數,調用該函數向服務器發起鏈接.該函數在收到服務器的贏大前,不會返回.這意味着TCP鏈接總會等待至少到服務器的一次往返時間. 2. 非阻塞I/O模型 非阻塞I/O 通過進程反復調用I/O函數(多次系統調用,並馬上返回);在數據拷貝的過程中,進程是阻塞的;我們把一個SOCKET接口設置爲非阻塞就是告訴內核,黨所請求的I/O操作無法完成時,不要將進程睡眠,而是返回一個錯誤,這樣我們的I/O操作函數將不斷的測試數據是否已經準備好了,如果沒有準備好,繼續測試,直到數據準備好爲止.在這個測試的過程中,會大量的佔用CPU的時間. 非阻塞套接字在控制建立的多個連接,在數據的收發量不均,時間不定時,明顯具有優勢.這種套接字在使用上存在一定難度,但只要排除這些困難,他在功能上還是非常強大的. 3. I/O復用模型 4. 信號驅動I/O模型5. 異步I/O模型6. 五種I/O模型比較 "},"docs/Node-process.html":{"url":"docs/Node-process.html","title":"进程与线程优性能","keywords":"","body":"Node.js 通过进程、线程优化的性能 1. node.js 单线程的特点 node.js 以异步非阻塞单线程，作为其执行速度的保障。什么是非阻塞单线程？ 高性能（不用考虑多线程间来回调用引起性能的损耗） 线程安全（不用担心同意变量会被多线程进行读写而造成程序的崩溃） 底层多线程 说node.js 是单线程其实也是不全面的，node.js 底层库会使用libuv调用多线程来处理I/O 操作。这就像食堂只有一个窗口，只能有按顺序一个个的接收点餐，但是后厨配菜的员工却有很多，他们各司其职保证出餐的速度。 2.如何通过多线程提高node.js 的性能 cluster: 为了利用多核系统，用户有时会想启动一个 Node.js 进程的集群去处理负载。 3. 如何通过多进程提高node.js 的性能 Child Process 创建进程 "},"docs/ServiceWorker-start.html":{"url":"docs/ServiceWorker-start.html","title":"ServiceWorker","keywords":"","body":"Service Worker native app 可以做到离线使用、消息推送、后台自动更新，service worker 的出现正是为了使得 web app 也可以具有类似的能力。 Service Worker 可以： 后台消息传递 网络代理，转发请求，伪造响应 离线缓存 消息推送 ... 生命周期 一个 service worker 要经历以下历程： 安装 激活，激活成功之后，打开chrome://inspect/#service-workers 可以查看当前运行的 service worker 监听 fetch 和 message 事件，下面两种事件会进行简要描述 销毁，是否销毁有浏览器决定，如果一个 service worker 长期不使用或者机器内存有限，则可能会销毁 worker fetch 事件 在页面发起 http 请求时， service worker 可以通过 fetch 事件拦截请求，并且给出自己的响应。 W3C提供了一个新的 fetch api，用于取代 XMLHttpRequest ，与XMLHttpRequest 最大的不同有两点： fetch() 方法返回的是 Promise 对象，通过then 方法进行连续调用，减少嵌套。 ES6 的 Promise 在成为标准之后，会越来越方便开发人员。 提供了 Request、Response 对象，如果做过后端开发，对 Request 、Response 应该比较熟悉。前端要发起请求可以通过 url 发起，也可以使用 Request 对象发起，而且 Request 可以复用。但是 Response 用在哪里呢？在service worker 出现之前，前端确实不会自己给自己发消息，但是有了 service worker，就可以在拦截请求之后根据需要返回自己的响应，对页面而言，这个普通的请求结果并没有区别，这是 Response 的一处应用。 /* 由于是get请求，直接把参数作为query string传递了 */ var URL = 'https://api.flickr.com/services/rest/?method=flickr.photos.search&api_key=your_api_key&format=json&nojsoncallback=1&tags=penguins'; function fetchDemo() { // fetch(url, option)支持两个参数，option中可以设置header、body、method信息 fetch(URL).then(function(response) { // 通过promise 对象获得相应内容，并且将响应内容按照json格式转成对象，json()方法调用之后返回的依然是promise对象 // 也可以把内容转化成arraybuffer、blob对象 return response.json(); }).then(function(json) { // 渲染页面 insertPhotos(json); }); } fetchDemo(); fetch api 与 XMLHttpRequest 相比，更加简洁，并且提供的功能更全面，资源获取方式比ajax更优雅。兼容性方面：chrome 42开始支持，对于旧浏览器，可以通过官方维护的polyfill支持。 message 事件 页面和 service worker 之间可以通过posetMessage() 方法发送消息，发送的消息可以通过 message事件接收到。 这是一个双向的过程，页面可以发消息给service worker，service worker也可以发送消息给页面，由于这个特性，可以将service worker作为中间纽带，使得一个域名或者子域名下的多个页面可以自由通信。 这里是一个小的页面之间通信demo 问题1. 运行时间 service worker并不是一直在后台运行的。在页面关闭后，浏览器可以继续保持service worker运行，也可以关闭service worker，这取决与浏览器自己的行为。所以不要定义一些全局变量， var hitCounter = 0; this.addEventListener('fetch', function(event) { hitCounter++; event.respondWith( new Response('Hit number ' + hitCounter) ); }); 返回的结果可能是没有规律的：1,2,1,2,1,1,2….，原因是hitCounter并没有一直存在，如果浏览器关闭了它，下次启动的时候hitCounter就赋值为0了 这样的事情导致调试代码困难，当你更新一个service worker以后，只有在打开新页面以后才可能使用新的service worker，在调试过程中经常等上一两分钟才会使用新的，比较抓狂。 问题2. 权限太大 当service worker监听fetch事件以后，对应的请求都会经过service worker。通过chrome的network工具，可以看到此类请求会标注：from service worker。如果service worker中出现了问题，会导致所有请求失败，包括普通的html文件。所以service worker的代码质量、容错性一定要很好才能保证web app正常运行。 "},"docs/nunjucks.html":{"url":"docs/nunjucks.html","title":"Nunjucks","keywords":"","body":"Nunjucks 模板 文件扩展名 任意扩展名来命名 Nunjucks 模板文件（建议 .njk）； 变量 undefined 或 null 不显示； 过滤器 模板继承 模板继承可以达到模板复用的效果，同时支持多层继承； 可以将继承的模板设为一个变量，这样可以动态指定继承的模板；这个变量既可以是个指向模板文件的字符串也可以是个模板编译后所生成的对象（需要添加上下文环境）。 super 通过调用 super 从而父级区块中的内容渲染到子区块中。 标签 if for Posts This would display if the 'item' collection were empty // 如果 items 数组是空数组的话则会渲染 else 语句中的内容 在循环中可获取一些特殊的变量： loop.index loop.index0 loop.revindex loop.revindex0 loop.first loop.last loop.length asyncEachasyncEach 为 for 的异步版本，只有当使用自定义异步模板加载器的时候才使用。 asyncAllasyncAll 和 asyncEach 类似，但 asyncAll 会并行的执行，并且每项的顺序仍然会保留。除非使用异步的过滤器、扩展或加载器，否则不要使用。 macro宏（macro） 可以定义可复用的内容，类似于编程语言中的函数. {% macro field(name, value='', type='test') %} {% endmacro %} set {% set standardModal %} {% include 'standardModalData.html' %} {% endset %} extendsextends 用来指定模板继承，被指定的模板为父级模板 block区块（block）定义了模板片段并标示一个名字，在模板继承中使用。父级模板可指定一个区块，子模板覆盖这个区块。 includeinclude 可以引入其他的模板，可以再多模板之间共享一些小模板，如果某个模板已使用了继承那么 include 将会非常有用。在某些情况下，我们可能希望在模板文件不存在时不要抛弃异常。对于这些情况，我们可以使用 ignore missing 来略过这些异常： {% include 'missing.html' ignore missing %} importimport 可加载不同的模板，可是你操作模板输出的数据，模板将会输出宏和在顶级作用域进行的赋值。被 import 进来的模板没有当前模板的上下文，所以无法使用当前模板的变量。 raw输出一些 Nunjucks 特殊的标签，可以使用 将所有的内容输出为纯文本。 filterfilter 区块允许我们使用区块中的内容来调用过滤器。不同于使用 | 语法，他会将区块渲染处的内容传递给过滤器。 callcall 区块允许你使用标签之间的内容来调用一个宏。这在你需要给宏传入大量内容时是十分有用的。在宏中，你可以通过caller() 来获取这些内容。 关键字参数 注释 {# and... #} 空白字符控制 你可以在开始和结束区块添加（-）来去除前面和后面的空白字符。 表达式 你可以使用和 javascript 一样的字面量 运算 Nunjucks 支持运算 比较 Logic and or not 可以使用大括号来分组If 表达式 和 javascript 的三元运算符一样，可使用if 的内联表达式函数调用（function Calls） 自定义转义 全局函数 range([start], stop, [step]) cycler(item1, item2, ...itemN) joiner([separator])内置过滤器 default(value, default, [boolean]) sort(arr, reverse, caseSens, attr) striptags(value, [preserve_linebreaks]) dump(object) "},"docs/Vim.html":{"url":"docs/Vim.html","title":"Vim Command Collection","keywords":"","body":"History Command 以:和/开头的命令都有历史记录，可以首先键入:或/然后按上下箭头来选择某个历史命令。 Start Vim 在命令行窗口中输入以下命令即可vim filename File Command vim file vim file1 file2 file3... :open file :split file :bn :bp :args :e ftp:192.168.10.76/abc.txt Insert Command i I Search Command Replacement Command Move Command Undo And Redo Delete Command Copy And Paste Cute Command Exit Command Window Command Shell Command Annotation Command Help Command Other Command "},"docs/WebSocket.html":{"url":"docs/WebSocket.html","title":"WebSocket","keywords":"","body":"WebSocket WebSocket 协议是基于TCP的一种新的网络协议。它实现了浏览器与服务器全双工（full-duplex）通信——允许服务其主动发送信息给客户端。 概述 The WebSocket Protocol enables two-way communication between a client running untrusted code in a controlled environment to a remote host that has opted-in to communications from that code. The security model used for this is the origin-based security model commonly used by web browsers. The protocol consists of an opening handshake followed by basic message framing, layered over TCP. The goal of this technology is to provide a mechanism for browser-based applications that need two-way communication with servers that does not rely on opening multiple HTTP connections (e.g., using XMLHttpRequest or s and long polling). WebSocket 协议支持（在受控环境中公运行不受信任的代码的）客户端与（选者加入该代码的通信的）远程主机之间进行全双工通信。用于此的安全模型是Web浏览器常用的基于原始的安全模式。协议包括一个开放的握手以及随后的TCP层上的消息帧。该技术的目标是为基于浏览器的、需要和服务器进行双向通信的（服务器不能依赖于打开多个HTTP链接（例如，使用 XMLHttpRequest 或和长轮询））应用程序提供一种通信机制。 产生背景 简单的说，WebSocket协议之前，双工通信是通过多个http链接来实现的，这导致了效率低下。WebSocket解决了这个问题。 下面是标准RFC6455中的产生背景概述。 长久以来，创建实现客户端和用户端之间双工通讯的web app 都会造成HTTP轮询的滥用：客户端向主机不断发送不同的HTTP呼叫来进行询问。 这会导致一系列问题： 服务器被迫为每个客户端使用许多不同的底层TCP连接：一个用于向客户端发送信息，其它用于接收每个传入消息。 有线协议有很高的开销，每个客户端和服务器之间都有HTTP头。 客户端脚本被迫维护从传出连接到传入连接的映射来追踪回复。 一个更简单的解决方案是使用单个TCP连接双向通信。这就是WebSocket协议所提供的功能。结合WebSocket API，WebSocket协议提供了一个用来替代HTTP轮询实现网页到远程主机的双向通信的方法。 WebSocket协议被设计来取代用HTTP作为传输层的双向通讯技术，这些技术只能牺牲效率和可依赖性其中一方来提高另一方，因为HTTP最初的目的不是为了双向通讯。 实现原理 在实现websocket连线过程中，需要通过浏览器发出websocket连线请求，然后服务器发出回应，这个过程通常称为‘握手’。在WebSocket API，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一个快速通道。两者之间就直接可以数据互相传送。在此WebSocket协议中，为我们实现及时服务带来了两大好处： Header互相沟通的Header是很小的-大概只有2Bytes Server Push服务器的推送，服务器不再被动的接收到浏览器的请求之后才返回数据，而是在有新数据时就主动推送给浏览器。 握手协议例子 浏览器请求 GET /webfin/websocket/ HTTP/1.1 Host: localhostUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: xqBt3ImNzJbYqRINxEFlkg==Origin: http://服务器地址Sec-WebSocket-Version: 13 服务器回应 HTTP/1.1 101 Switching Protocols Upgrade: websocketConnection: UpgradeSec-WebSocket-Accept: K7DJLdLooIwIG/MOpvWFB3y3FE8= HTML5 Web Socket API 在HTML5中内置有一些API，用于响应应用程序发起的请求。基本API语句如下： var ws = new WebSocket(url, name); //url为WebSocket服务器的地址，name 为发起握手协议的名称，为可选择项 ws.send(); ws.onmessage = (function () {...})(); ws.onerror = (function () {...})(); ws.close(); 浏览器以及语言支持 所有浏览器都支持RFC6455。但是具体的WebSocket版本有区别。php jetty netty ruby Kaazing nginx python Tomcat Django erlang netty .net等语言均可以用来实现支持WebSocket的服务器。 websocket api在浏览器端的广泛实现似乎只是一个时间问题了, 值得注意的是服务器端没有标准的api, 各个实现都有自己的一套api, 并且tcp也没有类似的提案, 所以使用websocket开发服务器端有一定的风险.可能会被锁定在某个平台上或者将来被迫升级。 "},"docs/TCP&IP.html":{"url":"docs/TCP&IP.html","title":"TCP/IP 协议","keywords":"","body":"TCP/IP协议 高楼大厦，起于平川。不积跬步,无以至千里，不积小流，无以成江海。 什么是TCP/IP 用于机器间通信，制定了各种各样的协议（TCP协议，DNS协议...），有了这些协议，各种数据流按照规则传输，计算机之间得以通信。 TCP/IP协议族中有一个重要的概念：分层，TCP/IP协议按照层次分为以下四层：应用层、传输层、网络层、数据链路层。（封转性、隔离） 下面是从网络上找到的TCP/IP通信数据流 HTTP 关系密切的协议：IP、TCP、和DNS IP协议：192.168.1.1这种数字指的是IP地址。IP协议的作用在于把各种数据包准确无误地传递给对方，其中重要的条件是IP地址和MAC地址（Media Access Control Address） 使用 ARP协议凭借MAC地址进行通信 IP 间的通信依赖 MAC 地址。在网络上，通信的双方在同一局域网（LAN）内的情况是很少的，通常是经过多台计算机和网络设备中转才能连接到对方。而在进行中转时，会利用下一站中转设备的 MAC 地址来搜索下一个中转目标。这时，会采用 ARP 协议（Address Resolution Protocol）。ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC 地址 你向另一台电脑发送一条信息，怎么在茫茫人海中瞬间找到对方，如下图所示： TCP协议：如果说IP协议是找到对方的详细地址。那么TCP协议就是把安全的东西带给对方。各有分工，互不冲突。 按层次分，TCP属于传输层，提供可靠的字节流服务。什么叫字节流服务呢？这个名字听起来让人不知所以然，下面听下我通俗的解释。所谓的字节流，其实就类似于信息切割。比如你是一个卖自行车的，你要去送货。安装好的自行车，太过庞大，又不稳定，容易损伤。不如直接把自行车拆开来，每个零件上都贴上收货人的姓名。最后送到后按照把属于同一个人的自行车再组装起来，这个拆解、运输、拼装的过程其实就是TCP字节流的过程。 我们看下严谨的学术表达是怎样的： 所谓的字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。而可靠的传输服务是指，能够把数据准确可靠地传给对方。一言以蔽之，TCP 协议为了更容易传送大数据才把数据分割，而且 TCP 协议能够确认数据最终是否送达到对方。 下面我写一段对话来模拟下这三次握手。为了确保信息能够确保准确无误的到达，TCP采用了著名的三次握手策略（three-way handshaking）.下面我写一段对话来模拟下这三次握手。 DNS：DNS(Domain names System) 和HTTP协议一样是处于应用层的服务，提供域名到IP地址之间的解析服务。 下面是我们访问一个网页，各种协议在里面气的作用: "},"docs/Http.html":{"url":"docs/Http.html","title":"HTTP 协议","keywords":"","body":"HTTP 协议 HTTP 协议 基础概念篇 协议详解篇 "},"docs/Http-base.html":{"url":"docs/Http-base.html","title":"基础概念篇","keywords":"","body":"Http 协议 基础概念篇 介绍 HTTP是Hyper Text Transfer Protocol(超文本传输协议)的缩写。它的发展是万维网协会（World Wide Web Consortinum）和Internet工作小组IETF（Internet Engineering Task Force）合作的结果，他们最终发布了一些列RFC，RFC 1945定义了HTTP/1.0版本。其中最著名的是 RFC2616。 RFC 2616 定义了今天普遍使用的一个版本—— HTTP 1.1。 HTTP协议（HyperText Transfer Protocol，超文本传输协议）是用于从WWW服务器传输超文本到本地浏览器的传送协议。他可以使浏览器更加高效，使网络传输减少，还确定传输文档中的哪一部分，以及哪部分内容首先显示（如文本先于图形）等。 在 TCP/IP 协议栈中的位置 HTTP协议通常承载于 TCP 协议之上，有时也承载于 TLS 或 SSL 协议层之上，这个时候就是我们常说的HTTPS。 如下图所示： HTTP 的请求响应模型 这样限制了 HTTP 协议，无法实现在客户端没有发起请求的时候，服务器将消息推送给客户端。 HTTP协议是一个无状态的协议，同一个客户端的这次请求和上次请求是没有对应关系的。 工作流程 一次 HTTP 操作称为一个事务。 使用 Wireshark 抓 TCP、 http 包 头域 每个头域有一个域名、冒号（:）和域值三部分组成。域名是大小写无关的，域值前可以坚决爱任何数量的空格符，头域可以被拓展为多行，在每行开始处，使用至少一个空格或制表符。 Host 头域 Host 头域指定请求资源的Internet主机和端口号，必须表示请求url的原始服务器或网关的位置。 HTTP/1.1 请求必须包含主机头域，否则系统会以400状态码返回。 Referer 头域 Referer 头域允许客户端指定请求 uri 的资源源地址，这可以允许服务器生成回退链表，可用来登录、优化cache等。他也允许废除的或错误的连接由于维护的目的被追踪。如果请求的uri没有自己的uri地址，Referer 不能被发送。如果指定的是部分 uri 地址，则此地址应该是一个相对地址。 User-Agent 头域 User-Agent 头域的内容包含发出请求的用户信息。 Cache-Control 头域 Cache-COntrol指定请求和响应遵循的缓存机制。在请求消息或响应消息中设置Cache-Control并不会修改另一个消息处理过程中的缓存处理过程。请求时的缓存指令包括：no-cache、 no-store、 max-age、 max-stale、 min-fresh、 only-if-cached 响应消息中的指令包括：public、 private、 no-cache、 no-store、 no-transform、 must-revalidate、 proxy-revalidate、 max-age Date 头域 Date头域表示消息发送的时间，时间描述格式由 RFC822 定义。 HTTP 的几个重要概念 连接： Connection 一个传输层的实际环流，他是建立在两个相互通讯的应用程序之间。 在 http1.1、 request、和response头中都有可能出现一个 connection 的头，此 header 的含义是当 client 和 server 通信时 对于长链接如何进行处理 。 在 http1.1 中， client 和 server 都是默认对方支持长连接的，如果 client 使用 http1.1 协议，但又不希望使用长连接，则需要在 header 中指明 connection的值为close；如果 server 方也不想支持长连接，则在response中也需要明确说明 connection 的值为 close。不论 request 还是 response 的 header 中包含了值为 close 的 connection，都表明当前正在使用的 tcp 链接在当天请求处理完毕后会被断掉。以后 client 再进行新的请求时就必须创建新的tcp链接了。 消息： Message HTTP 通讯的基本单位，包括一个结构化的八元组序列病通过连接接传输。 请求： Request 一个从客户端到服务器的请求信息包括应用于资源的方法、资源的标识符、资源的标识符和协议的版本号。 响应： Response 一个从服务器返回的信息包括 HTTP 协议的版本号、请求的状态和文档的 MIME 类型。 资源： Resource 由 URI 标识的网络数据对象或服务。 实体： Entity 数据资源或来自服务资源的回应的一种特殊表示方法，他可能被包围在一个请求或响应信息中。一个实体包括实体头信息和实体的本身内容。 客户机： Client 一个为发送请求目的而建立连接的应用程序。 用户代理： UserAgent 初始化一个请求的客户机。他们是浏览器、编辑器或其他用户工具。 服务器： Server 一个接收连接并对请求返回信息的应用程序。 源服务器： Originserver 是一个给定资源可以在其上驻留或被创建的服务器。 代理： Proxy 一个中间程序，他可以充当一个服务器，也可以充当一个客户机，为其他客户机建立请求。请求是通过可能的翻译在内部或经过传递到其他的服务器中。一个代理在发送请求信息之前，必须解释并且如果可能重写它。 代理经常作为通过防火墙的客户机端的门户，代理还可以作为一个帮助应用来通过协议处理没有被用户代理完成的请求。 网关： Gateway 一个作为其他服务器中间媒介的服务器。与代理不同的是，网关接受请求就好像对被请求的资源来说他就是源服务器；发出请求的客户机并没有意识到他在同网关打交道。 网关经常作为通过防火墙的服务器端的门户，网关还可以作为一个协议翻译器以便存取那些存储在非 HTTP 系统中的资源。 通道： Tunnel 是作为两个连接中继的中介程序。一旦激活，通道便认为不属于HTTP通讯，尽管通道可能是一个HTTP请求初始化的。当被中继的连接两端关闭时，通道便消失。当一个门户（Portal）必须存在或中介（Intermediary）不能解释中继的通讯时通道被经常使用。 缓存： Cache 反应信息的局域存储。 "},"docs/Http-detail.html":{"url":"docs/Http-detail.html","title":"协议详解篇","keywords":"","body":"Http 协议 协议详解篇 HTTP/1.0 和 HTTP/1.1 的比较 RFC HTTP version RFC1945 1.0 RFC2616 1.1 "},"docs/architectural.html":{"url":"docs/architectural.html","title":"架构设计经验分享","keywords":"","body":"架构设计经验分享 不要过设计： never over design 这是一个常常被提及的话题，但是只要想想你的架构里有多少功能是根本没有用到，或者最后废弃的，就能明白其重要性了，初涉架构设计，往往倾向于设计大而化一的架构，希望设计出具有无比扩展性，能适应一切需求的增加架构，web开发领域是个非常动态的过程，我们很难预测下个星期的变化，而又需要对变化做出最快最有效的响应。。 ebay的工程师说过，他们的架构设计从来都不能满足系统的增长，所以他们的系统永远都在推翻重做。请注意，不是ebay架构师的能力有问题，他们设计的架构总是建立旧版本的瓶颈上，希望通过新的架构带来突破，然而新架构带来的突破总是在很短的时间内就被新增需求淹没，于是他们不得不又使用新的架构 web开发，是个非常敏捷的过程，变化随时都在产生，用户需求千变万化，许多方面偶然性非常高，较之软件开发，希望用一个架构规划以后的所有设计，是不现实的。 web架构生命周期： web architecture's life cycle 缓存： Cache 核心模块一定要自己开发： 合理选择数据存储方式： 搞清楚谁是最重要的人： 不要执着于文档： 团队： "}}